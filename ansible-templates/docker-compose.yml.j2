services:
  #waf:
  #  image: owasp/modsecurity-crs:4.21.0-nginx-alpine-202512071012
  #  container_name: waf-proxy
  #  ports:
  #    - "80:8080"
  #  environment:
  #    - BACKEND=http://frontend:80
  #    - BACKEND_WS=ws://frontend:80/ws/
  #    - UPSTREAM_PORT=80
  #    - NGINX_ENTRYPOINT_QUIET_LOGS=1
  #    - MODSECURITY_RULE_ENGINE=On
  #    - PARANOIA=1
  #  volumes:
  #    - ../waf/custom-rules:/etc/nginx/custom-rules:ro
  #    - waf_logs:/var/log:ro
  #  networks:
  #    - hm_net
  #  depends_on:
  #    frontend:
  #      condition: service_healthy
  #  restart: unless-stopped

  db:
    image: postgres:17-alpine
    container_name: postgresql
    cpus: '1.0'
    mem_limit: '1g'
    expose:
      - "5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: "postgres"
      POSTGRES_PASSWORD: "postgres"
      POSTGRES_DB: "postgres"
    restart: always
    networks:
      - hm_net

  redis:
    image: redis:7.0.15
    container_name: redis
    cpus: '0.5'
    mem_limit: '512m'
    expose:
      - 6379
    volumes:
      - redis_data:/data
    environment:
      - REDIS_PASSWORD=rediska
    restart: always
    networks:
      - hm_net

  frontend:
    image: cr.selcloud.ru/hm-startup/hm-frontend:rolling
    cpus: '0.5'
    mem_limit: '512m'
    container_name: deadwood-frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    restart: always
    networks:
      - hm_net

  backend:
    image: cr.selcloud.ru/hm-startup/hm-backend:rolling
    cpus: '2.0'
    mem_limit: '2g'
    ports:
      - "8000:8000"
    environment:
      - POSTGRES_DB=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - DB_HOST=db
      - DB_PORT=5432
      - DJANGO_ENV=settings
      - API_HOST=deadwood.ru
      - API_PORT=8000
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://tempo:4317
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=none
      - OTEL_LOGS_EXPORTER=none
      - OTEL_SERVICE_NAME=deadwood
      - OTEL_RESOURCE_ATTRIBUTES=service.name=deadwood,service.namespace=sre
    depends_on:
      - db
      - redis
    volumes:
      - global_logs:/var/log/django:rw
    restart: always
    networks:
      - hm_net

  #worker:
  #  image: cr.selcloud.ru/hm-startup/hm-worker
  #  cpus: '1.0'
  #  mem_limit: '1g'
  #  environment:
  #    - POSTGRES_DB=postgres
  #    - POSTGRES_USER=postgres
  #    - POSTGRES_PASSWORD=postgres
  #    - DB_HOST=db
  #    - DB_PORT=5432
  #    - DJANGO_ENV=settings
  #    - API_HOST=127.0.0.1
  #    - API_PORT=80
  #    - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
  #    - OTEL_EXPORTER_OTLP_ENDPOINT=http://tempo:4318
  #    - OTEL_TRACES_EXPORTER=otlp
  #    - OTEL_METRICS_EXPORTER=none
  #    - OTEL_LOGS_EXPORTER=none
  #    - OTEL_SERVICE_NAME=deadwood
  #    - OTEL_RESOURCE_ATTRIBUTES=service.name=deadwood,service.namespace=dfir
  #  depends_on:
  #    - db
  #    - redis
  #  restart: always
  #  networks:
  #    - hm_net

  #beat:
  #  image: deadwood-beat:latest
  #  cpus: '1.0'
  #  mem_limit: '1g'
  #  environment:
  #    - POSTGRES_DB=postgres
  #    - POSTGRES_USER=postgres
  #    - POSTGRES_PASSWORD=postgres
  #    - DB_HOST=db
  #    - DB_PORT=5432
  #    - DJANGO_ENV=settings
  #    - API_HOST=127.0.0.1
  #    - API_PORT=80
  #    - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
  #    - OTEL_EXPORTER_OTLP_ENDPOINT=http://tempo:4318
  #    - OTEL_TRACES_EXPORTER=otlp
  #    - OTEL_METRICS_EXPORTER=none
  #    - OTEL_LOGS_EXPORTER=none
  #    - OTEL_SERVICE_NAME=deadwood
  #    - OTEL_RESOURCE_ATTRIBUTES=service.name=deadwood,service.namespace=dfir
  #  depends_on:
  #    - db
  #    - redis
  #  restart: always
  #  networks:
  #    - hm_net

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "127.0.0.1:11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: always
    networks:
      - hm_net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    expose:
      - "9090"
    restart: always
    networks:
      - hm_net
    depends_on:
      - backend
      - loki
      - promtail

  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    command: -config.file=/etc/loki/loki-config.yaml
    user: "0:0"
    volumes:
      - ./loki-config.yaml:/etc/loki/loki-config.yaml:ro
      - loki_data:/loki
    expose:
      - "3100"
    restart: always
    networks:
      - hm_net

  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    command: -config.file=/etc/promtail/promtail-config.yml
    volumes:
      - ./promtail-config.yml:/etc/promtail/promtail-config.yml:ro
      - global_logs:/var/log/django:ro
      - waf_logs:/var/log/waf:ro
    depends_on:
      - loki
    restart: always
    networks:
      - hm_net

  tempo:
    image: grafana/tempo:2.9.0
    container_name: tempo
    command: ["-config.file=/etc/tempo/tempo.yaml"]
    volumes:
      - ./tempo/tempo.yaml:/etc/tempo/tempo.yaml:ro
      - tempo_data:/var/tempo
    expose:
      - "3200"   # HTTP API / Tempo datasource для Grafana
      - "4318"   # OTLP HTTP от приложения
    restart: always
    networks:
      - hm_net

  grafana:
    image: grafana/grafana:11.0.0
    container_name: grafana
    depends_on:
      - prometheus
      - loki
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ueitdrg
      GF_SECURITY_ADMIN_PASSWORD: hwiuregfhwoeifwjipo3fjwoehfguwo8e4f
        #GF_SERVER_DOMAIN: localhost
        #GF_SERVER_ROOT_URL: "%(protocol)s://%(domain)s:%(http_port)s/"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    restart: always
    networks:
      - hm_net

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    network_mode: host
    pid: host
    command:
      - '--path.rootfs=/host'
    volumes:
      - '/:/host:ro,rslave'
      - '/proc:/host/proc:ro'
      - '/sys:/host/sys:ro'

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    restart: unless-stopped
    privileged: true
    devices:
      - /dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
      - /var/run/docker.sock:/var/run/docker.sock
    expose:
      - 8080
    networks:
      - hm_net

volumes:
  redis_data:
  postgres_data:
  ollama_data:
  loki_data:
  prometheus_data:
  grafana_data:
  tempo_data:
  global_logs:
  waf_logs:

networks:
  hm_net:
